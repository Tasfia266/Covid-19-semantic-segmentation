# -*- coding: utf-8 -*-
"""covid-19_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_QQpHx23_sCG3OKAJmjTb8rfRAfrng5a
"""

from google.colab import drive 
drive.mount ('/content/drive')

import os 
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import Adam 
import tensorflow as tf

seed=24 
batch_size=8 
from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_data_gen_args=  dict(rescale = 1/255.,
                         rotation_range=90,
                      width_shift_range=0.3,
                      height_shift_range=0.3,
                      shear_range=0.5,
                      zoom_range=0.3,
                      horizontal_flip=True,
                      vertical_flip=True,
                      fill_mode='reflect')

import numpy as np
mask_data_gen_args= dict (
    rescale=1/255., 
    rotation_range=90, 
    width_shift_range=0.3, 
    height_shift_range=0.3, 
    shear_range=0.5, 
    zoom_range=0.3, 
    horizontal_flip= True, 
    vertical_flip=True, 
    fill_mode= 'reflect', 
    preprocessing_function= lambda x: np.where (x>0, 1,0).astype (x.dtype)
)

image_data_generator= ImageDataGenerator (**img_data_gen_args)

train_dir='/content/drive/MyDrive/Data3/train_images'

image_generator= image_data_generator.flow_from_directory(train_dir, seed=seed, batch_size= batch_size, class_mode=None)

mask_data_generator= ImageDataGenerator (**mask_data_gen_args)

mask_generator= mask_data_generator.flow_from_directory ('/content/drive/MyDrive/Data3/train_mask', seed=seed, batch_size= batch_size, color_mode= 'grayscale', class_mode=None)

valid_img_generator= image_data_generator.flow_from_directory('/content/drive/MyDrive/Data3/val_images', seed=seed, batch_size= batch_size, class_mode=None)

valid_mask_generator= mask_data_generator.flow_from_directory ('/content/drive/MyDrive/Data3/val_mask', seed= seed, batch_size= batch_size, color_mode= 'grayscale', class_mode= None)

train_generator= zip (image_generator, mask_generator)

val_generator= zip (valid_img_generator, valid_mask_generator )

x= image_generator.next() 
y= mask_generator.next()

for i in range (0,1): 
  image= x[i] 
  mask= y[i] 
  plt.subplot (1,2,1)
  plt.imshow (image[:,:,0], cmap= 'gray') 
  plt.subplot (1,2,2) 
  plt.imshow (mask[:, :, 0])
  plt.show ()

! pip install focal-loss

# jaccard distnace loss mimics IOU 
from keras import backend as K 
def jaccard_distance_loss (y_true, y_pred, smooth=100): 
  #jaccard= (|x & y|)/ (|x| + |y| -|x & y|)
  intersection= K.sum (K.sum (K.abs (y_true*y_pred), axis=-1)) 
  sum= K.sum (K.sum (K.abs (y_true) +K.abs (y_pred), axis=-1)) 
  jac= (intersection+smooth) / (sum-intersection+smooth)
  return (1-jac)*smooth

# dice metrics is a great metrics to track accuracy in semantic segmentation 
def dice_metric (y_true, y_pred): 
  intersection= K.sum (K.sum (K.abs (y_true*y_pred), axis=-1)) 
  union= K.sum (K.sum (K.abs (y_true)+ K.abs (y_pred), axis=-1)) 
  return 2*intersection /union

IMG_HEIGHT= x.shape[1] 
IMG_WIDTH= x.shape[2]
IMG_CHANNEL = x.shape[3]

input_shape= (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL)

print (input_shape)

from keras.models import Model, load_model 
from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout 
from keras.layers.core import Lambda, RepeatVector, Reshape 
from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D
from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D 
from keras.layers.merge import concatenate, add 
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# U net architecture.
# Contracting path 
import keras  

model_in= Input (shape=(input_shape))
conv1= Conv2D (64, (3,3), activation='relu', padding='same')(model_in)
conv1= Conv2D (64, (3,3), activation='relu', padding='same')(conv1)
down1= MaxPooling2D ((2,2), strides=2)(conv1)

conv2= Conv2D (128, (3,3), activation='relu', padding='same')(down1)
conv2= Conv2D (128, (3,3), activation='relu', padding='same')(conv2)
down2= MaxPooling2D ((2,2), strides=2)(conv2)

conv3= Conv2D(256, (3,3), activation='relu', padding='same')(down2)
conv3= Conv2D(256, (3,3), activation='relu', padding='same')(conv3)
down3= MaxPooling2D((2,2), strides=2)(conv3)

conv4= Conv2D (512, (3,3), activation='relu', padding='same')(down3)
conv4= Conv2D (512, (3,3), activation='relu', padding='same')(conv4)
down4= MaxPooling2D((2,2), strides=2)(conv4)

conv5= Conv2D(1024, (3,3), activation='relu', padding='same')(down4)
conv5= Conv2D (1024, (3,3), activation='relu', padding='same')(conv5)

#Expensive path 
up1= UpSampling2D((2,2))(conv5)
conv6= Conv2D(512, (2,2), activation='relu', padding='same')(up1)
concate1= keras.layers.concatenate([conv4, conv6], axis=3)
conv6= Conv2D (512, (3,3), activation='relu', padding='same')(concate1)
conv6= Conv2D (512, (3,3), activation='relu', padding='same')(conv6)

up2= UpSampling2D((2,2))(conv6)
conv7= Conv2D(256, (2,2), activation='relu', padding='same')(up2)
concat2= keras.layers.concatenate([conv3, conv7], axis=3)
conv7= Conv2D (256, (3,3), activation='relu', padding='same')(concat2)
conv7= Conv2D (256, (3,3), activation='relu', padding='same')(conv7)

up3= UpSampling2D((2,2))(conv7)
conv8= Conv2D (128, (2,2), activation='relu', padding='same')(up3)
concat3=keras.layers.concatenate([conv2, conv8], axis=3)
conv8= Conv2D (128, (3,3), activation='relu', padding='same')(concat3)
conv8= Conv2D (128, (3,3), activation='relu', padding='same')(conv8)

up4= UpSampling2D ((2,2))(conv8)
conv9= Conv2D (64, (2,2), activation='relu', padding='same')(up4)
concat4= keras.layers.concatenate([conv1, conv9], axis=3)
conv9= Conv2D (64, (3,3), activation='relu', padding='same')(concat4)
conv9= Conv2D (64, (3,3), activation='relu', padding='same')(conv9)


conv10= Conv2D (1, (1,1), activation='sigmoid', padding='same')(conv9)
model= Model (model_in, conv10)

model.summary ()

from focal_loss import BinaryFocalLoss

model.compile (optimizer=Adam (lr=1e-3), loss= BinaryFocalLoss (gamma=2), metrics=[dice_metric])

num_train_images= len (os.listdir ('/content/drive/MyDrive/Data3/train_images/train'))

steps_per_epoch= num_train_images//batch_size

history= model.fit_generator (train_generator, validation_data= val_generator, steps_per_epoch= steps_per_epoch, validation_steps=steps_per_epoch, epochs=50)

model.save ('covid-19_segmentation.h5')

test_image_generator= image_data_generator.flow_from_directory ('/content/drive/MyDrive/Data3/test_images', seed=seed, batch_size=32, class_mode= None)

test_mask_generator= mask_data_generator.flow_from_directory('/content/drive/MyDrive/Data3/test_mask', seed= seed, batch_size=32, color_mode= 'grayscale', class_mode= None)

import random 
a= test_image_generator.next () 
b= test_mask_generator.next ()
test_image_number= random.randint (0,a.shape[0]-1 ) 
test_img= a[test_image_number]
ground_truth= b[test_image_number] 
test_img= np.expand_dims (test_img,0)

prediction= (model.predict (test_img)[0,:,:,0]>0.4).astype (np.uint8)

prediction.shape, test_img.shape

test_img_2= np.squeeze(test_img, axis=0) 
test_img_2.shape

plt.figure (figsize= (16,8)) 
plt.subplot (231) 
plt.title ('Testing Image') 
plt.imshow (test_img_2, cmap= 'gray') 
plt.subplot (232) 
plt.title ('Testing label') 
plt.imshow (ground_truth[:, :, 0], cmap= 'gray') 
plt.subplot (233) 
plt.title ('Prediction image') 
plt.imshow (prediction, cmap= 'gray') 

plt.show ()

